# JET-AI-AGENT

## Описание проекта


Ключевые возможности:
- Разделение проекта на модули и подгруппы (определенные в `config.py`).
- Создание контекстов для файлов (в папке `contexts`).
- Генерация саммари для директорий и модулей (в папке `modules_contexts`).
- Интерактивное меню для выбора действий (анализ файлов, генерация саммари).

Скрипт построен на Python, использует Ollama для AI-анализа и работает с предопределенными расширениями файлов (например, .java, .sql и т.д.).

## Структура кода

Проект состоит из трех основных файлов:

1. **analyzer_service.py**:
   - Отвечает за анализ кода через Ollama API.
   - Функция `analyze_code_block`: Собирает содержимое файлов (или контекстов), формирует промпт и отправляет запрос в Ollama. Возвращает результат анализа.
   - Используется как для создания контекстов файлов, так и для саммари директорий/модулей.

2. **config.py**:
   - Содержит настройки: пути, модели Ollama, промпты, поддерживаемые расширения файлов.
   - `MODULES`: Словарь с структурой модулей и подгрупп (пути к директориям для анализа).
   - Промпты (`FILE_PROMPT`, `DIR_PROMPT`, `MODULE_PROMPT`): Инструкции для AI по созданию контекстов и саммари.

3. **interactive_service.py**:
   - Основной скрипт с меню и логикой.
   - Функции для анализа файлов: `get_all_files_in_dir`, `analyze_files_in_dir`, `run_module_analysis`, `run_all_modules_analysis`.
   - Функции для саммари: `build_dir_summary_tree` (рекурсивно для директорий), `generate_module_summary` (для модулей).

## Как работает анализ файлов (создание контекстов)

Процесс анализа файлов происходит рекурсивно и создает контексты только для файлов с поддерживаемыми расширениями (из `SUPPORTED_EXTENSIONS` в `config.py`).

1. **Запуск анализа**:
   - Через меню: `[A]` для всех модулей или `[1]` для конкретного модуля.
   - Функция `run_module_analysis`: Перебирает подгруппы модуля (из `MODULES`), вызывает `analyze_files_in_dir` для каждого пути.

2. **Шаги в `analyze_files_in_dir`**:
   - Вычисляет относительный путь и создает соответствующую директорию в `contexts`.
   - Находит все файлы в директории рекурсивно (`get_all_files_in_dir`).
   - Для каждого файла:
     - Проверяет, существует ли контекст (`<filename>_context.txt`).
     - Если нет, формирует промпт (`FILE_PROMPT + имя файла`), вызывает `analyze_code_block` для анализа.
     - Сохраняет результат в `contexts/<относительный_путь>/<filename>_context.txt`.
   - Пропускает файлы больше `MAX_FILE_SIZE_KB` или не найденные.

3. **Пример**:
   - Для подгруппы `JIMCore` (путь `jim/JIM/JIMCore/src/main/java/su/jet/jim`):
     - Находит файлы, например, `Main.java`.
     - Создает `contexts/jim/JIM/JIMCore/src/main/java/su/jet/jim/Main_java_context.txt`.
   - Если контекст уже существует, выводит сообщение и пропускает.

## Как работает создание саммари (для директорий и модулей)

Саммари генерируются на основе существующих контекстов файлов в `contexts`. Процесс рекурсивный и создает развернутые описания логики директорий и модулей.

1. **Запуск генерации саммари**:
   - Через меню: `[G]` для всех модулей или `[1G]` для конкретного модуля.
   - Функция `generate_module_summary`: Вызывается для модуля, собирает саммари подгрупп и создает общее саммари модуля.

2. **Шаги в `generate_module_summary`**:
   - Перебирает подгруппы модуля (из `MODULES`).
   - Для каждой подгруппы:
     - Находит директорию в `contexts` (например, `contexts/jim/JIM/JIMCore/src/main/java/su/jet/jim`).
     - Вызывает `build_dir_summary_tree` для создания саммари директорий.
     - Собирает саммари подгрупп в строку.
   - Формирует промпт (`MODULE_PROMPT + имя модуля`), вызывает `analyze_code_block` для создания саммари модуля.
   - Сохраняет в `modules_contexts/<имя_модуля>/module_summary.txt`.

3. **Шаги в `build_dir_summary_tree` (рекурсивно для директорий)**:
   - Вычисляет путь для саммари в `modules_contexts` (например, `modules_contexts/jim/JIM/JIMCore/src/main/java/su/jet/jim/dir_summary.txt`).
   - Проверяет, существует ли `dir_summary.txt`; если да, пропускает.
   - Собирает:
     - Контексты файлов (`_context.txt`) из текущей директории.
     - Поддиректории: Рекурсивно вызывает себя для каждой (например, для `auth` в `contexts/jim/JIM/JIMCore/src/main/java/su/jet/jim/auth`).
   - Объединяет в `all_context`, формирует промпт (`DIR_PROMPT + имя директории`), вызывает `analyze_code_block`.
   - Сохраняет саммари в `dir_summary.txt`.
   - Рекурсия обеспечивает обработку вложенных директорий (например, `auth/subfolder`).

4. **Пример для модуля `mod_1_core`**:
   - Подгруппа `JIMCore` (путь `jim/JIM/JIMCore/src/main/java/su/jet/jim`).
   - В `contexts/jim/JIM/JIMCore/src/main/java/su/jet/jim` есть контексты файлов и поддиректория `auth`.
   - Сначала создается саммари для `auth` (`modules_contexts/.../auth/dir_summary.txt`).
   - Затем для корневой директории `jim` (`modules_contexts/.../jim/dir_summary.txt`), используя контексты файлов + саммари `auth`.
   - Наконец, саммари модуля в `modules_contexts/mod_1_core/module_summary.txt`, объединяя саммари всех подгрупп.

## Использование

1. **Подготовка**:
   - Установите Ollama: Скачайте с https://ollama.com/.
   - Запустите модель: `ollama pull gemma3:4b` (или другую, указанную в `config.py`).
   - Запустите сервер: `ollama serve`.
   - Установите зависимости: `pip install requests`.
   - Поместите проект (директорию с кодом IDM) рядом со скриптом или укажите путь как аргумент.

2. **Запуск скрипта**:
   - `python interactive_service.py [PROJECT_ROOT]` (например, `python interactive_service.py ../jim`).
   - Если путь не указан, используется `PROJECT_ROOT_FALLBACK = "../"`.

3. **Меню**:
   - `[A]`: Анализирует файлы во всех модулях и генерирует саммари (полный цикл).
   - `[G]`: Генерирует саммари для всех модулей (требует существующих контекстов файлов).
   - `[1]`: Анализирует файлы только для модуля `mod_1_core`.
   - `[1G]`: Генерирует саммари только для модуля `mod_1_core`.
   - Аналогично для других модулей.
   - `[E]`: Выход.

4. **Вывод**:
   - Контексты файлов: В `contexts/<относительный_путь>/<filename>_context.txt`.
   - Саммари директорий: В `modules_contexts/<относительный_путь>/dir_summary.txt`.
   - Саммари модулей: В `modules_contexts/<имя_модуля>/module_summary.txt`.

## Конфигурация и модификации

В `config.py` можно изменить:
- **Модели**: `MODEL_NAME_CODE` (для файлов), `MODEL_NAME_SUM` (для саммари). Увеличьте `NUM_PREDICT` для больших моделей.
- **Промпты**: `FILE_PROMPT`, `DIR_PROMPT`, `MODULE_PROMPT` — доработайте для более точных описаний.
- **Расширения**: `SUPPORTED_EXTENSIONS` — добавьте/уберите расширения файлов.
- **Структура модулей**: `MODULES` — добавьте/измените модули, подгруппы и пути. Например, добавьте новую подгруппу: `"1.7": {"name": "NewSub", "paths": ["path/to/new"], "model": MODEL_NAME_CODE}`.
- **Папки**: `CONTEXT_ROOT`, `MODULES_CONTEXTS_ROOT` — измените для хранения контекстов/саммари.
- **Ollama**: `OLLAMA_API_URL`, `MAX_FILE_SIZE_KB`, `TEMPERATURE` — настройки API.

**Как добавить новый модуль**:
- В `MODULES` добавьте новый ключ (например, `"6"`: `{ "name": "new_mod", "subgroups": { ... } }`).
- Запустите скрипт с опцией `[A]` для анализа.

**Как изменить промпты**:
- Отредактируйте текст в промптах, чтобы сделать описания более детальными или специфичными (например, добавить фокус на определенные аспекты логики).

## Дальнейшее развитие

Для начала пусть ниже будет описано мое видение работы данного агента:
  - Скрипт подключается к гиту продашкена ( так как в него попадает уже только чистый код )
  - При самом первом запуске идет обработка всех частей проекта
  - Создаются первые контексты по каждому файлу и каждой папки
  - Далее, при новом пуше в ветку идет анализ измененных или обновленных файлов и папок ( для этого нужно написать сервис )
  - Потом все затронутые папки и файлы прогоняются через агента для создания новых контекстов по ним
  - Таким образом, мы не обрабатываем весь проект заново, а только релевантные куски, что значительно уменьшает нагрузку на систему и время работы
  
Возможные доработки:
  - Сделать Reinforcement Learning, чтобы агент учился на замечаниях от наших разработчиков и дальше создавал документацию, которую от него ждут ( самообучался )