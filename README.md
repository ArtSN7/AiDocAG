# JET-AI-AGENT

---

## Стратегия анализа

Для документирования системы IDM кодовая база разделяется на логические группы и подгруппы. Каждая группа анализируется итеративно с учетом контекста для создания точной документации. Процесс включает:

1. Разделение файлов на модули (например, mod_1, mod_2 и т.д.) и подгруппы (например, mod_1.1, mod_1.2).
2. Первичный анализ подгрупп для создания начального контекста (КОНТЕКСТ_1).
3. Переход на уровень выше для создания КОНТЕКСТ_ГРУППЫ основываясь на КОНТЕКСТ_1, КОНТЕКСТ_2 ( контексты подгрупп )
4. Объединение всех контекстов для создания полной документации.

---

## Полезные знания

- Контекст группы будет показан как dir_context.txt в анализируемой папке
- В config.py можно менять следующие вещи:
  - MODEL_NAME_SUM , MODEL_NAME_CODE - это названия моделек ( можно поставить gemma3:27b условно )
  - NUM_PREDICT - можно менять количество предсказаний, увеличивая этот параметр (x2, x4, x8 и т.д.), сделать это обязательно при использовании более мощной модельки
  - SUPPORTED_EXTENSIONS - просто разрешения, которые поддерживаются скриптом
  - ?_PROMT - здесь лежат промты, которые можно дорабатывать, давать более точные указания и прочее
  - EXT - это либо txt , либо md ( для красивого вывода в гите )
    
---

## Запуск

1. Скачать ollama - https://ollama.com/ и положить в папку рядом с jim


```bash
ollama pull gemma3:4b
```

```bash
ollama serve
```

2. Установить Python and Libraries

```bash
pip install requests
```

3. Запуск скрипта

```bash
cd path/to/pyscript
python interactive_service.py
```


---

## Дальнейшее развитие 


Для начала пусть ниже будет описано мое видение работы данного агента:
  - Скрипт подключается к гиту продашкена ( так как в него попадает уже только чистый код )
  - При самом первом запуске идет обработка всех частей проекта
  - Создаются первые контексты по каждому файлу и каждой папки
  - Далее, при новом пуше в ветку идет анализ измененных или обновленных файлов и папок
  - Потом все затронутые папки и файлы прогоняются через агента для создания новых контекстов по ним
  - Таким образом, мы не обрабатываем весь проект заново, а только релевантные куски, что значительно уменьшает нагрузку на систему и время работы
  
Возможные доработки:
  - Сделать Reinforcement Learning, чтобы агент учился на замечаниях от наших разработчиков и дальше создавал документацию, которую от него ждут ( самообучался )
  - Удалить модули ( пути ) в config и сделать модельку, которая будет сама анализировать дерево проекта и решать по структуре файловой системы и контекстам 